{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName('recommendation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = pd.read_csv(\"../scraper/la_restaurant.csv\")\n",
    "sd = pd.read_csv('../scraper/san_diego_restaurant.csv')\n",
    "nyc = pd.read_csv('../scraper/NYC_restaurant.csv')\n",
    "sf = pd.read_csv('../scraper/sf_restaurant.csv')\n",
    "oc = pd.read_csv('../scraper/OC_restaurant.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([la,sd,oc,sf,nyc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, Wrangling and Prepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating']/10\n",
    "df = df[~df['restaurant'].str.contains('http')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning rating, user, and restuarant data for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, col, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_als(df, min_reviews):\n",
    "    \n",
    "    df_spark = spark.createDataFrame(df)\n",
    "\n",
    "    users = df_spark.select('user_name').distinct()\n",
    "    users = users.coalesce(1)\n",
    "    users = users.withColumn(\"user_id\", monotonically_increasing_id()).persist()\n",
    "    \n",
    "\n",
    "    rest = df_spark.select('restaurant').distinct()\n",
    "    rest = rest.coalesce(1)\n",
    "    rest = rest.withColumn('rest_id', monotonically_increasing_id()).persist()\n",
    "    \n",
    "    df_ids = df_spark.join(users,\"user_name\",\"left\").join(rest,'restaurant','left')\n",
    "    final_df = df_ids.select(col('user_id'), col('rest_id'),col('rating'))\n",
    "    \n",
    "    final_df = final_df.groupBy(['user_id','rest_id']).avg()\n",
    "    final_df = final_df.select(col('user_id'), col('rest_id'),col('avg(rating)').alias('rating'))\n",
    "    \n",
    "    users_spark = final_df.groupBy('user_id').count().filter(col('count')>=min_reviews).select('user_id')\n",
    "    users_spark_list = list(users_spark.toPandas()['user_id'])\n",
    "    \n",
    "    final_df = final_df[final_df.user_id.isin(users_spark_list)]\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = clean_for_als(df,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "---\n",
    "### 1) Numerical Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings descriptive statistics across all restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The amount of reviews per restuarant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['restaurant'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "review_counts = df['restaurant'].value_counts()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1,ncols=2, figsize=(13,5))\n",
    "axes[0].hist(df['rating'])\n",
    "axes[0].set_title('Ratings Distribution')\n",
    "axes[0].set_ylabel('Number of Ratings')\n",
    "axes[0].set_xlabel('Rating')\n",
    "\n",
    "axes[1].hist(review_counts, bins=18)\n",
    "axes[1].set_title('Review Counts Distribution')\n",
    "axes[1].set_ylabel('Number of Restaurants')\n",
    "axes[1].set_xlabel('Number of Reviews')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ratings and review counts are skewd to the left. The average rating is is a 4.26 while the max is a 5. More popular restuarants get the majority of the reviews. This is confirmed by the the mean for review counts by restaurant is 70 despite a 56 count being the 75th percentile. 75 percent of restuarants have less than 75 percent of total reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Categorical Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_rating_restaurant = df.groupby('restaurant')['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_count = df['restaurant'].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating_restaurant[top_by_count.index].plot.bar()\n",
    "plt.title('Average Rating per Most Reviewed Fast Food Restaurant')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_count.plot.bar()\n",
    "plt.title('Number of Reviews Per Most Reviewed Restaurant')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**Best Model**\")\n",
    "print(f\"RMSE =  {rmse}\")\n",
    "print(f\" Rank: {best2.rank}\")\n",
    "print(f\" MaxIter: {best2._java_obj.parent().getMaxIter()}\")\n",
    "print(f\" RegParam: {best2._java_obj.parent().getRegParam()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(df,min_reviews):\n",
    "    models = {}\n",
    "    rmses = {}\n",
    "    for i in min_reviews:\n",
    "        final = clean_for_als(df,i)\n",
    "        (train,test) = final.randomSplit([0.8,0.2])\n",
    "\n",
    "        als = ALS(userCol=\"user_id\" , itemCol=\"rest_id\", ratingCol=\"rating\",coldStartStrategy=\"drop\",\n",
    "                  nonnegative = True, implicitPrefs = False) \n",
    "\n",
    "        param_grid = ParamGridBuilder().addGrid(als.rank,[15,18,20]).addGrid(als.maxIter, [18,19]).addGrid(als.regParam, [.12,.13]).build()\n",
    "\n",
    "        evaluator = RegressionEvaluator(metricName='rmse',labelCol='rating',predictionCol='prediction')\n",
    "\n",
    "        cv = CrossValidator(estimator = als, estimatorParamMaps = param_grid, evaluator = evaluator, numFolds = 5)\n",
    "\n",
    "        model = cv.fit(train)\n",
    "        \n",
    "        best = model.bestModel\n",
    "        predictions = best.transform(test)\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        \n",
    "        models[i] = best\n",
    "        rmses[i] = rmse\n",
    "        \n",
    "    return models, rmses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_reviews = [4,5,6,7,8,9]\n",
    "\n",
    "models, rmses = grid_search(df,min_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1.13989692922892,\n",
       " 5: 1.1377484693801205,\n",
       " 6: 1.1454884849460252,\n",
       " 7: 1.1791340256260716,\n",
       " 8: 1.1503140768512947,\n",
       " 9: 1.169544231246566}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 minimum review yielded the lowest rmse errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_min = min(rmses.keys(), key=(lambda k: rmses[k]))\n",
    "best = models[key_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Best Model**\n",
      "RMSE =  1.1377484693801205\n",
      " Rank: 20\n",
      " MaxIter: 19\n",
      " RegParam: 0.13\n"
     ]
    }
   ],
   "source": [
    "print(\"**Best Model**\")\n",
    "print(f\"RMSE =  {rmses[key_min]}\")\n",
    "print(f\" Rank: {best.rank}\")\n",
    "print(f\" MaxIter: {best._java_obj.parent().getMaxIter()}\")\n",
    "print(f\" RegParam: {best._java_obj.parent().getRegParam()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = clean_for_als(df, key_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|rest_id|rating|\n",
      "+-------+-------+------+\n",
      "|  50717|    251|   5.0|\n",
      "|  58914|    435|   5.0|\n",
      "|  51780|    158|   5.0|\n",
      "|   7420|    477|   5.0|\n",
      "|  21945|    218|   4.0|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
